import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
})

const ASSISTANT_ID = process.env.OPENAI_ASSISTANT_ID_ROLEPLAY || ''

export async function POST(request: NextRequest) {
  try {
    const body = await request.json()
    const { threadId, message, config } = body

    console.log('ğŸ“¨ RequisiÃ§Ã£o recebida:', { threadId, hasMessage: !!message, hasConfig: !!config })

    // Validar API Key
    if (!process.env.OPENAI_API_KEY) {
      return NextResponse.json({ error: 'OpenAI API Key nÃ£o configurada' }, { status: 500 })
    }

    // Validar Assistant ID
    if (!ASSISTANT_ID) {
      return NextResponse.json({ error: 'Assistant ID nÃ£o configurado' }, { status: 500 })
    }

    // CASO 1: Criar nova thread (inÃ­cio do roleplay)
    if (!threadId && config) {
      console.log('ğŸ­ Criando nova sessÃ£o de roleplay...')
      console.log('ğŸ“‹ Config:', config)

      const thread = await openai.beta.threads.create()
      console.log('âœ… Thread criada:', thread.id)

      // Montar mensagem de contexto
      const objectionsList = config.objections?.length > 0
        ? config.objections.join(', ')
        : 'Nenhuma objeÃ§Ã£o especÃ­fica'

      const contextMessage = `VocÃª estÃ¡ em uma simulaÃ§Ã£o de venda. CaracterÃ­sticas do cliente:
- Idade: ${config.age} anos
- Temperamento: ${config.temperament}
- Segmento: ${config.segment}
- ObjeÃ§Ãµes: ${objectionsList}

Interprete este personagem e inicie a conversa como cliente.`

      console.log('ğŸ“ Enviando contexto...')

      // Adicionar contexto Ã  thread
      await openai.beta.threads.messages.create(thread.id, {
        role: 'user',
        content: contextMessage,
      })

      // Executar assistant
      console.log('ğŸš€ Executando assistant...')
      const run = await openai.beta.threads.runs.createAndPoll(thread.id, {
        assistant_id: ASSISTANT_ID,
      })

      console.log('âœ… Run completado:', run.status)

      if (run.status === 'completed') {
        const messages = await openai.beta.threads.messages.list(thread.id)
        const lastMessage = messages.data[0]
        const responseText = lastMessage.content[0].type === 'text'
          ? lastMessage.content[0].text.value
          : 'Erro ao obter resposta'

        console.log('ğŸ’¬ Resposta:', responseText)

        return NextResponse.json({
          threadId: thread.id,
          message: responseText,
        })
      } else {
        throw new Error(`Run status: ${run.status}`)
      }
    }

    // CASO 2: Continuar conversa existente
    if (threadId && message) {
      console.log('ğŸ’¬ Continuando conversa:', threadId)

      // Adicionar mensagem do vendedor
      await openai.beta.threads.messages.create(threadId, {
        role: 'user',
        content: message,
      })

      // Executar assistant e aguardar resposta
      const run = await openai.beta.threads.runs.createAndPoll(threadId, {
        assistant_id: ASSISTANT_ID,
      })

      if (run.status === 'completed') {
        const messages = await openai.beta.threads.messages.list(threadId)
        const lastMessage = messages.data[0]
        const responseText = lastMessage.content[0].type === 'text'
          ? lastMessage.content[0].text.value
          : 'Erro ao obter resposta'

        console.log('âœ… Resposta:', responseText)

        return NextResponse.json({
          threadId,
          message: responseText,
        })
      } else {
        throw new Error(`Run status: ${run.status}`)
      }
    }

    return NextResponse.json({ error: 'RequisiÃ§Ã£o invÃ¡lida' }, { status: 400 })

  } catch (error: any) {
    console.error('âŒ Erro:', error)
    return NextResponse.json(
      {
        error: 'Erro ao processar mensagem',
        details: error?.message || 'Erro desconhecido',
      },
      { status: 500 }
    )
  }
}
