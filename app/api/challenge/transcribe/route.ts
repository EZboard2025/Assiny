import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
})

// Prompt de contexto para o desafio "Venda uma Pedra"
// Isso ajuda o Whisper a entender melhor o contexto e transcrever com mais precis√£o
const CHALLENGE_CONTEXT_PROMPT = `Contexto: Conversa de vendas em portugu√™s brasileiro.
Um vendedor est√° tentando vender uma pedra antiga para um homem de campo.
Termos comuns: pedra, quintal, av√¥, fazenda, campo, ro√ßa, decora√ß√£o, jardim, propriedade, valor sentimental, antiguidade, rel√≠quia, pre√ßo, comprar, vender, neg√≥cio, interesse.
O cliente pode mencionar: trabalho de campo, an√°lise, coleta, materiais naturais, pesquisa.`

export async function POST(request: NextRequest) {
  try {
    console.log('üì® Requisi√ß√£o de transcri√ß√£o do Challenge recebida')
    const formData = await request.formData()
    const audioFile = formData.get('audio') as File

    if (!audioFile) {
      console.error('‚ùå Arquivo de √°udio n√£o encontrado no FormData')
      return NextResponse.json({ error: 'Arquivo de √°udio n√£o encontrado' }, { status: 400 })
    }

    console.log('üé§ Transcrevendo √°udio do Challenge:')
    console.log('  - Nome:', audioFile.name)
    console.log('  - Tamanho:', audioFile.size, 'bytes')
    console.log('  - Tipo:', audioFile.type)

    if (audioFile.size === 0) {
      console.error('‚ùå Arquivo de √°udio vazio')
      return NextResponse.json({ error: 'Arquivo de √°udio vazio' }, { status: 400 })
    }

    // Transcrever usando OpenAI Whisper com contexto do desafio
    const transcription = await openai.audio.transcriptions.create({
      file: audioFile,
      model: 'whisper-1',
      language: 'pt',
      prompt: CHALLENGE_CONTEXT_PROMPT,
    })

    console.log('‚úÖ Transcri√ß√£o completa:', transcription.text)

    if (!transcription.text || transcription.text.trim() === '') {
      console.log('‚ö†Ô∏è Transcri√ß√£o vazia retornada pela API')
      return NextResponse.json({ text: '', warning: 'Transcri√ß√£o vazia' })
    }

    return NextResponse.json({
      text: transcription.text,
    })

  } catch (error: any) {
    console.error('‚ùå Erro ao transcrever:', error)
    return NextResponse.json(
      {
        error: 'Erro ao transcrever √°udio',
        details: error?.message || 'Erro desconhecido',
      },
      { status: 500 }
    )
  }
}
