import OpenAI from 'openai'
import { createClient } from '@supabase/supabase-js'
import { PlaybookAdherence } from './evaluateRoleplay'

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })

const supabaseAdmin = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
)

export interface SimpleChallengeEvaluation {
  overall_score: number
  performance_level: 'poor' | 'needs_improvement' | 'good' | 'very_good' | 'excellent' | 'legendary'
  executive_summary: string
  criteria_scores: {
    need_identification: number
    value_creation: number
    objection_handling: number
    closing_skills: number
    communication: number
  }
  top_strengths: string[]
  areas_to_improve: string[]
  key_moments: Array<{
    moment: string
    analysis: string
    suggestion: string
  }>
  coaching_feedback: string
  playbook_adherence?: PlaybookAdherence
}

export interface SimpleChallengeParams {
  transcription: string
  companyId?: string | null
}

const SYSTEM_PROMPT = `Voc√™ √© um avaliador especializado em t√©cnicas de vendas, focado em avaliar simula√ß√µes do tipo "Venda uma Caneta" ou desafios similares de vendas r√°pidas.

Sua fun√ß√£o √© avaliar a performance do vendedor com base em crit√©rios pr√°ticos de vendas.

CRIT√âRIOS DE AVALIA√á√ÉO (0-10 cada):

1. IDENTIFICA√á√ÉO DE NECESSIDADES (need_identification)
0-3: N√£o tentou descobrir necessidades do cliente
4-6: Fez perguntas b√°sicas mas n√£o aprofundou
7-8: Identificou necessidades espec√≠ficas do cliente
9-10: Descobriu necessidades que o pr√≥prio cliente n√£o sabia que tinha

2. CRIA√á√ÉO DE VALOR (value_creation)
0-3: Focou apenas em caracter√≠sticas do produto
4-6: Mencionou alguns benef√≠cios gen√©ricos
7-8: Conectou benef√≠cios √†s necessidades do cliente
9-10: Criou valor √∫nico e personalizado

3. TRATAMENTO DE OBJE√á√ïES (objection_handling)
0-3: Ignorou ou reagiu mal √†s obje√ß√µes
4-6: Respondeu de forma gen√©rica
7-8: Tratou obje√ß√µes com t√©cnica adequada
9-10: Transformou obje√ß√µes em oportunidades

4. HABILIDADE DE FECHAMENTO (closing_skills)
0-3: N√£o tentou fechar ou foi agressivo demais
4-6: Tentou fechar sem prepara√ß√£o adequada
7-8: Usou t√©cnica de fechamento apropriada
9-10: Fechamento natural e confiante

5. COMUNICA√á√ÉO (communication)
0-3: Comunica√ß√£o confusa ou inadequada
4-6: Comunica√ß√£o b√°sica mas funcional
7-8: Clara, persuasiva e adaptada ao cliente
9-10: Excepcional, criou conex√£o genu√≠na

C√ÅLCULO DO SCORE GERAL:
OVERALL_SCORE = (need_identification + value_creation + objection_handling + closing_skills + communication) / 5

Arredonde para uma casa decimal.

N√çVEIS DE PERFORMANCE:
0-4: poor
4.1-5.9: needs_improvement
6-7: good
7.1-8: very_good
8.1-9: excellent
9.1-10: legendary

FORMATO DE RESPOSTA (JSON):
{
  "overall_score": n√∫mero de 0-10,
  "performance_level": "poor|needs_improvement|good|very_good|excellent|legendary",
  "executive_summary": "2-3 par√°grafos resumindo a performance",
  "criteria_scores": {
    "need_identification": 0-10,
    "value_creation": 0-10,
    "objection_handling": 0-10,
    "closing_skills": 0-10,
    "communication": 0-10
  },
  "top_strengths": ["for√ßa 1", "for√ßa 2"],
  "areas_to_improve": ["√°rea 1", "√°rea 2"],
  "key_moments": [
    {
      "moment": "descri√ß√£o do momento",
      "analysis": "o que aconteceu",
      "suggestion": "o que poderia ser melhor"
    }
  ],
  "coaching_feedback": "Feedback motivacional e construtivo de 2-3 frases"
}

REGRAS IMPORTANTES PARA SUGEST√ïES:
- Esta √© uma SIMULA√á√ÉO de vendas, N√ÉO uma liga√ß√£o real
- N√ÉO sugira "praticar sil√™ncio", "fazer pausas", "deixar o cliente processar" ou similar - isso n√£o se aplica a simula√ß√µes
- N√ÉO sugira t√©cnicas que dependem de tempo real ou intera√ß√£o presencial
- Foque em sugest√µes sobre: estrutura do pitch, argumenta√ß√£o, perguntas, tratamento de obje√ß√µes, linguagem usada
- Todas as sugest√µes devem ser aplic√°veis em um contexto de simula√ß√£o/roleplay de texto

Seja objetivo e forne√ßa feedback acion√°vel.`

const USER_PROMPT_TEMPLATE = `Avalie a seguinte transcri√ß√£o de um desafio de vendas:

TRANSCRI√á√ÉO:
{transcription}

Analise a performance do vendedor e retorne a avalia√ß√£o no formato JSON especificado.`

const PLAYBOOK_SECTION = `

=== CARD: PLAYBOOK ADHERENCE ===

CONTEXTO DA EMPRESA:
- Nome da empresa: {company_name}
- Descri√ß√£o da empresa: {company_description}
- Tipo da empresa: {company_type}

A empresa possui o seguinte PLAYBOOK DE VENDAS:

--- IN√çCIO DO PLAYBOOK ---
{playbook_content}
--- FIM DO PLAYBOOK ---

OBJETIVO DO CARD PLAYBOOK ADHERENCE:
Este card avalia a ader√™ncia do vendedor √†s regras ESPEC√çFICAS do playbook que N√ÉO s√£o cobertas pelos crit√©rios de avalia√ß√£o acima.

O que este card AVALIA - 5 DIMENS√ïES:

1. ABERTURA (opening)
- Apresenta√ß√£o conforme script do playbook
- Uso de gancho espec√≠fico
- Pedido de tempo/permiss√£o
- Primeiros 30-60 segundos

2. FECHAMENTO (closing)
- Pr√≥ximo passo concreto definido
- Data/hora espec√≠fica agendada
- Recapitula√ß√£o de acordos
- Compromisso claro do prospect

3. CONDUTA (conduct)
- Regras de comportamento seguidas
- Proibi√ß√µes respeitadas
- Tom e linguagem adequados
- Escuta ativa demonstrada

4. SCRIPTS OBRIGAT√ìRIOS (required_scripts)
- Frases espec√≠ficas que a empresa exige
- Perguntas padronizadas utilizadas
- Respostas-padr√£o aplicadas corretamente

5. PROCESSO (process)
- Etapas obrigat√≥rias do funil seguidas
- Qualifica√ß√£o conforme crit√©rios da empresa
- Documenta√ß√£o/registro mencionado
- Handoff adequado (se aplic√°vel)

INSTRU√á√ïES PARA AVALIA√á√ÉO:

PASSO 1: Extrair crit√©rios do playbook
Extraia APENAS crit√©rios que se encaixam nas 5 dimens√µes acima.

PASSO 2: Classificar cada crit√©rio
type:
- required: linguagem imperativa ("deve", "sempre", "obrigat√≥rio")
- recommended: linguagem sugestiva ("recomendado", "ideal", "prefira")
- prohibited: linguagem negativa ("nunca", "n√£o", "evitar", "proibido")

weight:
- critical: marcado como cr√≠tico, essencial, ou pode causar perda de deal
- high: enfatizado, tem se√ß√£o dedicada
- medium: mencionado como boa pr√°tica
- low: sugest√£o, nice-to-have

PASSO 3: Avaliar cada crit√©rio
result | Quando usar | points_earned
compliant | Executou corretamente | 100
partial | Executou com falhas | 50
missed | N√£o executou | 0
violated | Fez o oposto (para prohibited) | -50
not_applicable | Contexto n√£o permitiu avaliar | N/A

PASSO 4: Calcular scores
Score por dimens√£o:
score = (Œ£ points_earned √ó weight_multiplier) / (Œ£ max_points √ó weight_multiplier) √ó 100

weight_multiplier: critical=3, high=2, medium=1, low=0.5

Score geral (pesos das dimens√µes):
- opening: 20%
- closing: 25%
- conduct: 20%
- required_scripts: 20%
- process: 15%

adherence_level:
- exemplary: 90-100%
- compliant: 70-89%
- partial: 50-69%
- non_compliant: 0-49%

REGRAS ESPECIAIS:
1. Se playbook n√£o menciona uma dimens√£o: marque como not_evaluated e exclua do c√°lculo
2. Se call foi interrompida: avalie apenas o poss√≠vel e indique no coaching_notes
3. Viola√ß√µes s√£o sempre reportadas mesmo com score bom
4. Momentos exemplares merecem destaque em exemplary_moments

Inclua no JSON de resposta o campo "playbook_adherence":
{
  "playbook_adherence": {
    "overall_adherence_score": 0-100,
    "adherence_level": "non_compliant|partial|compliant|exemplary",

    "dimensions": {
      "opening": {
        "score": 0-100,
        "status": "not_evaluated|missed|partial|compliant|exemplary",
        "criteria_evaluated": [
          {
            "criterion": "descri√ß√£o do crit√©rio extra√≠do do playbook",
            "type": "required|recommended|prohibited",
            "weight": "critical|high|medium|low",
            "result": "compliant|partial|missed|violated|not_applicable",
            "evidence": "trecho da transcri√ß√£o ou 'n√£o encontrado'",
            "points_earned": 0-100,
            "notes": "observa√ß√£o adicional se necess√°rio"
          }
        ],
        "dimension_feedback": "1-2 frases sobre performance na abertura"
      },
      "closing": { "score": 0-100, "status": "...", "criteria_evaluated": [...], "dimension_feedback": "..." },
      "conduct": { "score": 0-100, "status": "...", "criteria_evaluated": [...], "dimension_feedback": "..." },
      "required_scripts": { "score": 0-100, "status": "...", "criteria_evaluated": [...], "dimension_feedback": "..." },
      "process": { "score": 0-100, "status": "...", "criteria_evaluated": [...], "dimension_feedback": "..." }
    },

    "violations": [
      {
        "criterion": "regra violada",
        "type": "prohibited",
        "severity": "critical|high|medium|low",
        "evidence": "trecho exato da transcri√ß√£o",
        "impact": "impacto potencial da viola√ß√£o",
        "recommendation": "como corrigir"
      }
    ],

    "missed_requirements": [
      {
        "criterion": "requisito n√£o cumprido",
        "type": "required",
        "weight": "critical|high|medium|low",
        "expected": "o que deveria ter acontecido",
        "moment": "momento da call onde deveria ter ocorrido",
        "recommendation": "como implementar"
      }
    ],

    "exemplary_moments": [
      {
        "criterion": "crit√©rio executado de forma exemplar",
        "evidence": "trecho da transcri√ß√£o",
        "why_exemplary": "por que foi acima do esperado"
      }
    ],

    "playbook_summary": {
      "total_criteria_extracted": 0,
      "criteria_compliant": 0,
      "criteria_partial": 0,
      "criteria_missed": 0,
      "criteria_violated": 0,
      "criteria_not_applicable": 0,
      "critical_criteria_met": "X de Y",
      "compliance_rate": "XX%"
    },

    "coaching_notes": "1-2 par√°grafos com orienta√ß√µes espec√≠ficas para o vendedor melhorar ader√™ncia ao playbook"
  }
}
`

export async function evaluateSimpleChallenge(params: SimpleChallengeParams): Promise<SimpleChallengeEvaluation> {
  const { transcription, companyId } = params

  console.log('üéØ Iniciando avalia√ß√£o de desafio simples via OpenAI...')

  // Vari√°veis para contexto do playbook
  let companyName = 'N√£o informado'
  let companyDescription = 'N√£o informado'
  let companyType = 'N√£o informado'
  let playbookContent: string | null = null

  // Buscar dados da empresa e playbook se companyId fornecido
  if (companyId) {
    // Buscar nome da empresa
    const { data: company } = await supabaseAdmin
      .from('companies')
      .select('name')
      .eq('id', companyId)
      .single()

    if (company?.name) {
      companyName = company.name
    }

    // Buscar tipo da empresa (B2B/B2C)
    const { data: typeData } = await supabaseAdmin
      .from('company_type')
      .select('type')
      .eq('company_id', companyId)
      .single()

    if (typeData?.type) {
      companyType = typeData.type
    }

    // Buscar dados da empresa
    const { data: companyData } = await supabaseAdmin
      .from('company_data')
      .select('descricao')
      .eq('company_id', companyId)
      .single()

    if (companyData?.descricao) {
      companyDescription = companyData.descricao
    }

    // Buscar playbook da empresa
    const { data: playbook } = await supabaseAdmin
      .from('sales_playbooks')
      .select('content')
      .eq('company_id', companyId)
      .eq('is_active', true)
      .single()

    if (playbook?.content) {
      playbookContent = playbook.content
      console.log('üìñ Playbook encontrado, incluindo na avalia√ß√£o do desafio')
    }
  }

  // Montar prompt do usu√°rio
  let userPrompt = USER_PROMPT_TEMPLATE.replace('{transcription}', transcription)

  // Se houver playbook, adicionar se√ß√£o de an√°lise
  if (playbookContent) {
    userPrompt += PLAYBOOK_SECTION
      .replace('{company_name}', companyName)
      .replace('{company_description}', companyDescription)
      .replace('{company_type}', companyType)
      .replace('{playbook_content}', playbookContent)
  }

  const response = await openai.chat.completions.create({
    model: 'gpt-4.1',
    messages: [
      { role: 'system', content: SYSTEM_PROMPT },
      { role: 'user', content: userPrompt }
    ],
    response_format: { type: 'json_object' },
    temperature: 0.5,
    max_tokens: 6000
  })

  const content = response.choices[0].message.content

  if (!content) {
    throw new Error('OpenAI retornou resposta vazia')
  }

  console.log('‚úÖ Avalia√ß√£o de desafio simples conclu√≠da')

  const evaluation = JSON.parse(content) as SimpleChallengeEvaluation

  // Se n√£o tinha playbook, garantir que playbook_adherence n√£o exista
  if (!playbookContent && evaluation.playbook_adherence) {
    delete evaluation.playbook_adherence
  }

  if (evaluation.playbook_adherence) {
    console.log('üìñ Playbook Adherence - Score:', evaluation.playbook_adherence.overall_adherence_score + '%', '| Level:', evaluation.playbook_adherence.adherence_level)
  }

  return evaluation
}
