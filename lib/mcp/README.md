# MCP - Model Context Protocol

## ğŸ“‹ O que Ã© o MCP?

O MCP (Model Context Protocol) Ã© a camada de abstraÃ§Ã£o que gerencia toda comunicaÃ§Ã£o entre os usuÃ¡rios e o agente de IA. Ele:

- ğŸ§  MantÃ©m contexto das conversas
- ğŸ“Š Analisa progresso do usuÃ¡rio
- ğŸ¯ Personaliza respostas baseado no perfil
- ğŸ’¾ Salva histÃ³rico no banco de dados
- ğŸ”„ Gerencia fluxo de conversaÃ§Ã£o

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   UsuÃ¡rio   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ChatInterface  â”‚ (React Component)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    useChat      â”‚ (React Hook)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AIAgent       â”‚ (MCP Core)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚Supabaseâ”‚ â”‚ IA APIâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Componentes Principais

### 1. Types (`types.ts`)

Define todas as interfaces TypeScript:

```typescript
// Mensagem no chat
interface MCPMessage {
  role: 'user' | 'assistant' | 'system'
  content: string
  timestamp: Date
  metadata?: Record<string, any>
}

// Contexto do usuÃ¡rio
interface MCPContext {
  userId: string
  userName?: string
  userRole: 'admin' | 'vendedor'
  conversationHistory: MCPMessage[]
  currentModule?: string
  userProgress?: UserProgressContext
}
```

### 2. Agent (`agent.ts`)

Classe principal que gerencia a IA:

```typescript
class AssinyAIAgent implements AIAgent {
  // Processar mensagens
  async processMessage(request: MCPRequest): Promise<MCPResponse>

  // Recomendar mÃ³dulos
  async getTrainingRecommendations(userId: string): Promise<TrainingModule[]>

  // Analisar desempenho
  async analyzePerformance(userId: string): Promise<UserProgressContext>
}
```

## ğŸ“š Como Usar

### No React Component

```typescript
import { useChat } from '@/lib/hooks/useChat'

function ChatComponent() {
  const { messages, sendMessage, loading } = useChat(userId)

  const handleSend = async (text: string) => {
    const response = await sendMessage(text)
    console.log('SugestÃµes:', response?.suggestions)
  }

  return (
    <div>
      {messages.map((msg, i) => (
        <div key={i}>{msg.content}</div>
      ))}
    </div>
  )
}
```

### Integrar com API de IA

Edite o mÃ©todo `generateResponse` em `agent.ts`:

#### Exemplo com OpenAI:

```typescript
private async generateResponse(
  systemPrompt: string,
  conversationContext: string,
  message: string
): Promise<MCPResponse> {
  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: 'gpt-4',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: message }
      ]
    })
  })

  const data = await response.json()

  return {
    message: data.choices[0].message.content,
    metadata: {
      confidence: 0.9,
      needsEscalation: false
    }
  }
}
```

#### Exemplo com Anthropic (Claude):

```typescript
private async generateResponse(
  systemPrompt: string,
  conversationContext: string,
  message: string
): Promise<MCPResponse> {
  const response = await fetch('https://api.anthropic.com/v1/messages', {
    method: 'POST',
    headers: {
      'x-api-key': process.env.ANTHROPIC_API_KEY,
      'anthropic-version': '2023-06-01',
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: 'claude-3-sonnet-20240229',
      system: systemPrompt,
      messages: [
        { role: 'user', content: message }
      ],
      max_tokens: 1024
    })
  })

  const data = await response.json()

  return {
    message: data.content[0].text,
    metadata: {
      confidence: 0.9,
      needsEscalation: false
    }
  }
}
```

## ğŸ¯ PersonalizaÃ§Ã£o do Contexto

O agente usa informaÃ§Ãµes do usuÃ¡rio para personalizar respostas:

```typescript
const systemPrompt = `
VocÃª Ã© um assistente de treinamento da Assiny.

Contexto do usuÃ¡rio:
- Nome: ${context.userName}
- FunÃ§Ã£o: ${context.userRole}
- MÃ³dulos completados: ${context.userProgress?.completedModules}
- Score: ${context.userProgress?.currentScore}
- Pontos fracos: ${context.userProgress?.weakPoints.join(', ')}
- Pontos fortes: ${context.userProgress?.strengths.join(', ')}

Adapte suas respostas baseado neste contexto.
`
```

## ğŸ“Š AnÃ¡lise de Performance

```typescript
const performance = await aiAgent.analyzePerformance(userId)

console.log({
  completedModules: performance.completedModules,
  totalModules: performance.totalModules,
  currentScore: performance.currentScore,
  weakPoints: performance.weakPoints,
  strengths: performance.strengths
})
```

## ğŸ”„ RecomendaÃ§Ãµes de MÃ³dulos

```typescript
const recommendations = await aiAgent.getTrainingRecommendations(userId)

recommendations.forEach(module => {
  console.log(`${module.title} - ${module.description}`)
})
```

## ğŸš€ PrÃ³ximos Passos

1. **Integrar API de IA**
   - Adicionar variÃ¡veis de ambiente com API keys
   - Implementar mÃ©todo `generateResponse` real
   - Testar respostas

2. **Melhorar AnÃ¡lise de Performance**
   - Adicionar mais mÃ©tricas
   - Criar grÃ¡ficos de progresso
   - Comparar com mÃ©dia da equipe

3. **Adicionar Features AvanÃ§adas**
   - Streaming de respostas
   - SugestÃµes contextuais
   - AnÃ¡lise de sentimento
   - DetecÃ§Ã£o de dÃºvidas frequentes

4. **OtimizaÃ§Ãµes**
   - Cache de respostas comuns
   - Rate limiting
   - CompressÃ£o de contexto
   - Parallel processing

## ğŸ“ VariÃ¡veis de Ambiente NecessÃ¡rias

Adicione ao `.env.local`:

```bash
# IA Provider (escolha um)
OPENAI_API_KEY=sk-...
# ou
ANTHROPIC_API_KEY=sk-ant-...
# ou
GOOGLE_AI_API_KEY=...

# ConfiguraÃ§Ãµes opcionais
AI_MODEL=gpt-4
AI_MAX_TOKENS=2000
AI_TEMPERATURE=0.7
```

## ğŸ› Debug

Ative logs detalhados:

```typescript
// Em agent.ts
const DEBUG = process.env.NODE_ENV === 'development'

if (DEBUG) {
  console.log('System Prompt:', systemPrompt)
  console.log('User Message:', message)
  console.log('Context:', context)
}
```

## ğŸ“– Recursos

- [OpenAI API Docs](https://platform.openai.com/docs)
- [Anthropic Claude API](https://docs.anthropic.com/claude/reference)
- [Supabase Realtime](https://supabase.com/docs/guides/realtime)